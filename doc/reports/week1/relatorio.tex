\documentclass[a4paper,10pt]{article}

\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[top=1.0in,bottom=1.0in]{geometry}
\usepackage{hyperref}
\usepackage[singlelinecheck=false]{caption}
\usepackage[backend=biber,url=true,doi=true,eprint=false]{biblatex}

\addbibresource{../common/references.bib}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\titleformat{\section}
  {\normalfont\scshape\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\scshape\bfseries}{\thesubsection}{1em}{}
\titleformat{\paragraph}
  {\normalfont}{\theparagraph}{1em}{}
\titleformat{\subparagraph}
  {\normalfont}{\thesubparagraph}{1em}{}

\captionsetup[table]{labelsep=space}

\theoremstyle{plain}

\newtheorem*{spn-def}{Definição}

\title{\textbf{Modeling and Reasoning with Bayesian Networks: Compiling Bayesian Networks}}

\begin{document}
\date{}
\author{}
\vspace*{-40pt}
{\let\newpage\relax\maketitle}

Relatório semana 1 - MAC0215 (Atividade Curricular em Pesquisa)

Aluno: Renato Lui Geh (Bacharelado em Ciência da Computação)

Orientador: Denis Deratani Mauá

\section{Atividades realizadas na semana}

\paragraph{
  Durante a semana foram lidos os seguintes tópicos do livro \textit{Modeling and Reasoning with
Bayesian Networks}\cite{bayes-net-darwiche}:
}

\begin{description}
  \item[12] - Compiling Bayesian Networks
  \begin{description}
    \item[12.1] - Introduction
    \item[12.2] - Circuit semantics
    \item[12.3] - Circuit propagation
    \begin{description}
      \item[12.3.1] - Evaluation and differentiation passes
    \end{description}
  \end{description}
\end{description}

\section{Definição das atividades}

\paragraph{
  Foram estudados o processo de se compilar Redes Bayesianas em circuitos aritméticos, algumas 
notações usadas em Redes Bayesianas, a definição de uma \textit{network polynomial}, algumas 
propriedades de Redes Bayesianas e diferenciação de uma rede a partir de uma evidência.
}

\paragraph{
  Esta seção será dividida em subseções para cada subtópico citado na seção anterior. Cada 
subseção é um resumo do que foi estudado em cada tópico, contendo os assuntos mais importantes
para o projeto.
}

\subsection{Introduction}

\paragraph{
  Aqui apresentaremos algumas notações usadas em Redes Bayesianas - e que podem ser extendidas para
outros Modelos Gráficos Probabilísticos (PGM).
}

\begin{figure}[h]
\centering\includegraphics[scale=0.5]{imgs/fig1.png}
\caption{Uma Rede Bayesiana $A \to B$. Em Redes Bayesianas uma aresta representa uma dependência.
  No caso da imagem $A$ depende de $B$. As CPTs associadas a esse grafo estão em Tabela 1 e 
  Tabela 2.}
\end{figure}

\begin{table}[h]
\begin{center}
\captionsetup{justification=centering}
\caption{ e Tabela 2}
\begin{tabular}{c | c}
  A  & $\Theta_A$ \\
\hline
true & $\theta_a = 0.3$ \\
false& $\theta_{\overline{a}} = 0.7$ \\
\end{tabular}
\quad
\quad
\begin{tabular}{c c | c}
A & B & $\Theta_{B|A}$ \\
\hline
true & true & $\theta_{b|a} = 0.1$ \\
true & false & $\theta_{\overline{b}|a} = 0.9$ \\
false & true & $\theta_{b|\overline{a}} = 0.8$ \\
false & false & $\theta_{\overline{b}|\overline{a}} = 0.2$ \\
\end{tabular}
\end{center}
\end{table}

\paragraph{
  Antes de começarmos com circuitos aritméticos, vamos primeiro apresentar algumas definições
importantes.
}

\paragraph{
  Chamamos de CPT (Conditional Probability Table) as tabelas que representam as
probabilidades de uma rede (ex.: as CPTs da Rede Bayesiana na Figura 1 são as Tabelas 1 e 2).
Pode-se claramente ver que para $n$ nós de uma Rede Bayesiana, precisamos de uma quantidade
exponencial $2^n$ de probabilidades para representar cada instância de variáveis.
}

\paragraph{
  Chamamos de MPE (Most Probable Explanation) a instância mais provável de variáveis que aceitam
uma evidência. Mais formalmente dizemos que:
}

\begin{spn-def} Sejam $X_1,...,X_n$ as variáveis da rede e $e$ a evidência dada. Existe uma
  instância $x_1,...,x_n$ onde $Pr(x_1,...,x_n|e)$ é maximal. Chamamos $x_1,...,x_n$ a 
  \textit{explicação mais provável} (\textit{most probable explanation}) dado $e$.
\end{spn-def}

\paragraph{
  Chamamos de MAP (Maximum A Posteriori hypothesis) quando a probabilidade de uma certa instância
é maximal.
}

\begin{spn-def} Sejam $X$ o conjunto de todas as variáveis da rede e $M$ um subconjunto qualquer
  dessas variáveis. Dado uma evidência $e$, qualquer instância $m$ de variáveis $M$ onde $Pr(m|e)$
  é maximal é uma \textit{hipótese máxima a posteriori} (\textit{maximum a posteriori hypothesis}).
\end{spn-def}

\paragraph{
  $M$ também é chamado de variáveis MAP. MPE é uma MAP quando as variáveis MAP incluem todas as
variáveis da rede.
}

\paragraph{
  Agora que temos uma base podemos voltar para circuitos aritméticos. Dado um circuito aritmético 
que representa uma Rede Bayesiana, teremos dois tipos de entradas: variáveis $\theta$, que 
chamaremos de \textit{parâmetros}, e as variáveis $\lambda$, que chamaremos de 
\textit{indicadores}. Parâmetros são valorados de acordo com a CPT da rede, enquanto indicadores
são valorados de acordo com a evidência. Nas próximas subseções veremos que podemos ter duas
passagens pelo circuito. Uma em que vamos de baixo para cima (bottom-up) para calcular a 
probabilidade de uma dada evidência, e outra em que vamos de cima para baixo (top-down), chamada
de \textit{differentiation pass} para calcularmos as derivadas parciais de cada entrada do 
circuito.
}

\subsection{Circuit semantics}

\paragraph{
  Ao compilarmos um circuito aritmético de uma Rede Bayesiana estamos representando, de forma 
compacta, a distribuição de probabilidade induzida da rede. No caso da Figura 1, a distribuição de
probabilidade está representada na Tabela 3.
}

\setcounter{table}{2}

\begin{table}[h]
\begin{center}
\captionsetup{justification=centering}
\caption{}
\begin{tabular}{c c | c}
$A$ & $B$ & $Pr(A, B)$ \\
\hline
$a$ & $b$ & $\theta_{a}\theta_{b|a}$ \\
$a$ & $\overline{b}$ & $\theta_{a}\theta_{\overline{b}|a}$ \\
$\overline{a}$ & $b$ & $\theta_{\overline{a}}\theta_{b|\overline{a}}$ \\
$\overline{a}$ & $\overline{b}$ & $\theta_{\overline{a}}\theta_{\overline{b}|\overline{a}}$ \\
\end{tabular}
\end{center}
\end{table}

\newpage

\paragraph{
  Multiplicando cada $Pr(A, B)$ com as suas respectivas variáveis indicadoras temos que:
}

\begin{table}[h]
\begin{center}
\captionsetup{justification=centering}
\caption{}
\begin{tabular}{c c | c}
$A$ & $B$ & $Pr(A, B)$ \\
\hline
$a$ & $b$ & $\lambda_{a}\lambda_{b}\theta_{a}\theta_{b|a}$ \\
$a$ & $\overline{b}$ & $\lambda_{a}\lambda_{\overline{b}}\theta_{a}\theta_{\overline{b}|a}$ \\
$\overline{a}$ & $b$ & $\lambda_{\overline{a}}\lambda_{b}\theta_{\overline{a}}\theta_{b|\overline{a}}$ \\
$\overline{a}$ & $\overline{b}$ & $\lambda_{\overline{a}}\lambda_{\overline{b}}\theta_{\overline{a}}\theta_{\overline{b}|\overline{a}}$ \\
\end{tabular}
\end{center}
\end{table}

\paragraph{
  Somando todas as probabilidades da distribuição temos:
}

\begin{equation}
f = \lambda_{a}\lambda_{b}\theta_{a}\theta_{b|a} + 
  \lambda_{a}\lambda_{\overline{b}}\theta_{a}\theta_{\overline{b}|a} +
  \lambda_{\overline{a}}\lambda_{b}\theta_{\overline{a}}\theta_{b|\overline{a}} +  
  \lambda_{\overline{a}}\lambda_{\overline{b}}\theta_{\overline{a}}\theta_{\overline{b}|\overline{a}}
\end{equation}

\paragraph{
  Chamamos a função $f$ de \textit{network polynomial}, que representa a distribuição de 
probabilidade da rede na Figura 1. Para computar a probabilidade dada qualquer evidência $e$,
definimos cada variável indicadora de forma consistente com a evidência. Vamos definir o que
significa definir uma variável de forma consistente com uma evidência:
}

\begin{spn-def} Sejam um conjunto $X=\{x_1,...,x_n,\overline{x}_1,...,\overline{x}_n\}$ das 
variáveis da rede e uma evidência $e=\{e_p,...,e_q\}$. Dizemos que $X$ está consistente com $e$ 
quando para cada $e_i$, se $e_i=1$ então $x_i=1$ e $\overline{x}_i=0$; e se $e_i=0$ então $x_i=0$ 
e $\overline{x}_i=1$. Para todo $j$ tal que $1\leq{j}\leq{n}$ e que não exista um $e_j \in e$
definiremos $x_j=\overline{x}_j=1$. Por questões de visibilidade, definimos $x_i, \overline{x}_i$
ao invés de $\lambda_{i}, \lambda_{\overline{i}}$, porém ambas as notações são equivalentes.
\end{spn-def}

\paragraph{
  Portanto, se por exemplo tivermos evidência $e=\overline{a}$, teremos na \textit{network 
polynomial} da Figura 1 os seguintes indicadores: $\lambda_{a}=0, \lambda_{\overline{a}}=1,
\lambda_{b}=1, \lambda_{\overline{b}}=1$. Neste exemplo, o valor de $f$ seria:
}

\begin{equation}
\begin{split}
f(\textbf{e}=\overline{a}) & = (0)(1)\theta_{a}\theta_{b|a} + (0)(1)\theta_{a}\theta_{\overline{b}|a} +
  (1)(1)\theta_{\overline{a}}\theta_{b|\overline{a}} + 
  (1)(1)\theta_{\overline{a}}\theta_{\overline{b}|\overline{a}} \\
& = \theta_{\overline{a}}\theta_{b|\overline{a}} + \theta_{\overline{a}}\theta_{\overline{b}|\overline{a}} \\
& = Pr(\textbf{e})
\end{split}
\end{equation}

\paragraph{
  Como a \textit{network polynomial} de uma rede é a distribuição de probabilidade da rede, então
seu tamanho é exponencial. O circuito aritmético é uma representação compacta de $f$. Em alguns
casos $f$ não pode ser limitado, enquanto que o circuito pode.
}

\paragraph{
  Vamos definir formalmente uma \textit{network polynomial}, mas antes vamos definir algumas
notações. Dizemos que $$
}

\newpage

\printbibliography

\end{document}
